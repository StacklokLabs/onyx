FROM python:3.11.7-slim-bookworm

LABEL com.danswer.maintainer="founders@onyx.app"
LABEL com.danswer.description="This image is for the Onyx model server which runs all of the \
AI models for Onyx. This container and all the code is MIT Licensed and free for all to use. \
You can find it at https://hub.docker.com/r/onyx/onyx-model-server. For more details, \
visit https://github.com/onyx-dot-app/onyx."

# Default ONYX_VERSION, typically overriden during builds by GitHub Actions.
ARG ONYX_VERSION=0.0.0-dev
ENV ONYX_VERSION=${ONYX_VERSION} \
    DANSWER_RUNNING_IN_DOCKER="true"


RUN echo "ONYX_VERSION: ${ONYX_VERSION}"

COPY ./requirements/model_server.txt /tmp/requirements.txt
RUN pip install --no-cache-dir --upgrade \
        --retries 5 \
        --timeout 30 \
        -r /tmp/requirements.txt

RUN apt-get remove -y --allow-remove-essential perl-base && \ 
    apt-get autoremove -y

# Pre-downloading models for setups with limited egress
# Set environment variable to control HuggingFace cache location
ENV HF_HOME=/root/.cache/huggingface_downloads

# Download and process models one at a time with cleanup
RUN set -ex; \
    mkdir -p /root/.cache/huggingface_final; \
    for MODEL in \
        "distilbert-base-uncased" \
        "mixedbread-ai/mxbai-rerank-xsmall-v1" \
        "onyx-dot-app/hybrid-intent-token-classifier" \
        "onyx-dot-app/information-content-model" \
        "nomic-ai/nomic-embed-text-v1"; \
    do \
        echo "Processing model: $MODEL"; \
        python -c "from huggingface_hub import snapshot_download; snapshot_download('$MODEL', local_dir='/root/.cache/huggingface_final/$MODEL')"; \
        rm -rf /root/.cache/huggingface_downloads/*; \
    done; \
    # Initialize SentenceTransformer separately
    python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer(model_name_or_path='nomic-ai/nomic-embed-text-v1', trust_remote_code=True)"; \
    # Move final cache to temp location
    mv /root/.cache/huggingface_final /root/.cache/temp_huggingface; \
    # Cleanup
    rm -rf /root/.cache/huggingface_downloads

WORKDIR /app

# Utils used by model server
COPY ./onyx/utils/logger.py /app/onyx/utils/logger.py
COPY ./onyx/utils/middleware.py /app/onyx/utils/middleware.py

# Place to fetch version information
COPY ./onyx/__init__.py /app/onyx/__init__.py

# Shared between Onyx Backend and Model Server
COPY ./shared_configs /app/shared_configs

# Model Server main code
COPY ./model_server /app/model_server

ENV PYTHONPATH=/app

CMD ["uvicorn", "model_server.main:app", "--host", "0.0.0.0", "--port", "9000"]
